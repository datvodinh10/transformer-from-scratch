{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/datvodinh10/Transformer/blob/main/Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KS54xB-55S-9"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !git clone https://github.com/datvodinh10/Transformer-From-Scratch.git\n",
        "# %cd Transformer-From-Scratch\n",
        "# !pip -q install transformers #just for the tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xa86aZe5S_A"
      },
      "outputs": [],
      "source": [
        "from src.lib import *\n",
        "from src.transfomer import *"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "E48jURLS5S_C"
      },
      "source": [
        "## Get data and Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtjfLwsu5S_C"
      },
      "outputs": [],
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLqbPnAR5S_C"
      },
      "outputs": [],
      "source": [
        "s = \"Hello my name is Dat\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4s_Wou-5S_D"
      },
      "outputs": [],
      "source": [
        "tokens = tokenizer.tokenize(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hHvyksJ5S_D"
      },
      "outputs": [],
      "source": [
        "tokenizer.convert_tokens_to_ids(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8oCNWT85S_D"
      },
      "outputs": [],
      "source": [
        "tokenizer.decode(tokenizer.convert_tokens_to_ids(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDItes_J5S_D"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "root = \"./data\"\n",
        "for path, subdirs, files in os.walk(root):\n",
        "    for name in files:\n",
        "        with open(os.path.join(path, name),'r') as f:\n",
        "            data+=tokenizer.convert_tokens_to_ids(tokenizer.tokenize(f.read()))\n",
        "\n",
        "    \n",
        "            \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sduvFRaa5S_F"
      },
      "outputs": [],
      "source": [
        "print(tokenizer.decode(data[:20]))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = torch.tensor(data,device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3T4k8K715S_G"
      },
      "outputs": [],
      "source": [
        "model = TransformerModel(\n",
        "            vocab_size=tokenizer.vocab_size,\n",
        "            embed_size=384,\n",
        "            heads=6,\n",
        "            num_layers=6,\n",
        "            max_len=1000,\n",
        "            device=device,\n",
        "            decode_vocab=tokenizer.decode,\n",
        "            dropout=0.2,\n",
        "            lr=6e-4,\n",
        "            batch_size=1,\n",
        "            block_size=256,\n",
        "            n_iter=100_000,\n",
        "            print_every=100\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Total params: {sum(p.numel() for p in model.parameters())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.fit(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "context = torch.zeros((1,1),dtype=torch.long,device=device)\n",
        "# context = train_data[:50].reshape(1,-1).to(device)\n",
        "model.inference(context, max_token=100)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "torchenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
