{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lib import *\n",
    "from src.transfomer import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prepocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/Shakespeare.txt\",'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_to_idx = {char:idx for idx,char in enumerate(chars)}\n",
    "idx_to_str = {idx:char for idx,char in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = lambda s :[str_to_idx[i] for i in s]\n",
    "decode = lambda l : \"\".join([idx_to_str[i] for i in l ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_encoded = encode(text)\n",
    "text_encoded = torch.tensor(text_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.9\n",
    "n = int(p * len(text_encoded))\n",
    "train_data = text_encoded[0:n]\n",
    "test_data = text_encoded[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1003854]), torch.Size([111540]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape,test_data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4074, 0.0000, 0.0000],\n",
       "        [0.0485, 0.1007, 0.0000],\n",
       "        [0.0533, 0.3183, 0.6602]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B,T,C = 4,8,2\n",
    "torch.tril(torch.rand(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
       "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
       "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
       "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
       "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
       "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(\n",
    "    vocab_size=vocab_size,\n",
    "    embed_size=384,\n",
    "    heads=4,\n",
    "    num_layers=4,\n",
    "    max_len=1000,\n",
    "    device=device,\n",
    "    decode_vocab=decode,\n",
    "    dropout=0.2,\n",
    "    lr=6e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16620737\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citi'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(train_data[:10].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0 Loss: 4.076231479644775\n",
      "First Citizen:\n",
      "Before we proceed any further, hearnAoexlee isnM kCrHh?t r zrZC:U3vBl-der?kkpYn&D!eNk----------------------------------\n",
      "Iter: 20 Loss: 3.12453031539917\n",
      "First Citizen:\n",
      "Before we proceed any further, hearkeup\n",
      "reldC Cens\n",
      "\n",
      "mkFtk o trsrk :Yh\n",
      " iietzpai l trf----------------------------------\n",
      "Iter: 40 Loss: 3.116227388381958\n",
      "First Citizen:\n",
      "Before we proceed any further, hearspehpuo\n",
      ",oo\n",
      "hasP eeeCeat\n",
      "rirr\n",
      "r a \n",
      "e,t pnYa:zeersl----------------------------------\n",
      "Iter: 60 Loss: 3.1151316165924072\n",
      "First Citizen:\n",
      "Before we proceed any further, heareettdu \n",
      "pifepeaey\n",
      "eeC.\n",
      "eoro   : o:C\n",
      "n ehzfe \n",
      "kt hi----------------------------------\n",
      "Iter: 80 Loss: 3.1147220134735107\n",
      "First Citizen:\n",
      "Before we proceed any further, heartrYpei:  ehthee enCki \n",
      "fllrkr\n",
      "ioz irz Brelatzpstii----------------------------------\n",
      "Iter: 100 Loss: 3.1144745349884033\n",
      "First Citizen:\n",
      "Before we proceed any further, hearsFree:o rr\n",
      ".dippee\n",
      "t\n",
      "t\n",
      "tekh siiprispzf eiue frstk.----------------------------------\n",
      "Iter: 120 Loss: 3.1142940521240234\n",
      "First Citizen:\n",
      "Before we proceed any further, hearwp\n",
      "ol,Aue\n",
      "  SFpt i e Ceu\n",
      "t,pnspees: ,\n",
      "hSaiwr\n",
      "ih k\n",
      "----------------------------------\n",
      "Iter: 140 Loss: 3.1141598224639893\n",
      "First Citizen:\n",
      "Before we proceed any further, hearklrtaoorkAteieFar Fzie,e .phe tle rrsfkkfkc\n",
      "Bht\n",
      "ka----------------------------------\n",
      "Iter: 160 Loss: 3.114053964614868\n",
      "First Citizen:\n",
      "Before we proceed any further, hearu\n",
      "pwee pye \n",
      "\n",
      ", aaFno,kAts,soufno\n",
      ", aBtkCzutu suzto----------------------------------\n",
      "Iter: 180 Loss: 3.1139700412750244\n",
      "First Citizen:\n",
      "Before we proceed any further, heareiee\n",
      "i:lrederse\n",
      "deoeirpikeeams ,eeeeyteS:tyrlep.pt----------------------------------\n",
      "Iter: 200 Loss: 3.1139023303985596\n",
      "First Citizen:\n",
      "Before we proceed any further, hearY.epe:p i peekiprmh\n",
      "hte.kewpeso epetfiaFrtsahaeeCt----------------------------------\n",
      "Iter: 220 Loss: 3.11384654045105\n",
      "First Citizen:\n",
      "Before we proceed any further, hear\n",
      "\n",
      "tea :   \n",
      "tee\n",
      "\n",
      "orruCe hrn \n",
      "e\n",
      "YuiohAkCr \n",
      ":aio,Sia\n",
      "----------------------------------\n",
      "Iter: 240 Loss: 3.1138014793395996\n",
      "First Citizen:\n",
      "Before we proceed any further, hear seenu\n",
      "wheuzFio:eA  sA\n",
      "\n",
      " e l es.nfhdCete:nBp eu:hp----------------------------------\n",
      "Iter: 260 Loss: 3.113762617111206\n",
      "First Citizen:\n",
      "Before we proceed any further, hear\n",
      "odopYCaSpcAe urfhu seArsfl hnmtonAeahehzr\n",
      "Azoa:k,----------------------------------\n",
      "Iter: 280 Loss: 3.113729476928711\n",
      "First Citizen:\n",
      "Before we proceed any further, hearez,s\n",
      "iecor o::ukpSr\n",
      ":e,orYSs FnC,e fiYrt\n",
      "eoau pi.e----------------------------------\n",
      "Iter: 300 Loss: 3.1137032508850098\n",
      "First Citizen:\n",
      "Before we proceed any further, hearaee ez::atr.eeezfeCYtpei i\n",
      " eau:Ne  eatsae:ewezeir----------------------------------\n",
      "Iter: 320 Loss: 3.113677740097046\n",
      "First Citizen:\n",
      "Before we proceed any further, hearYe Betf,ure so\n",
      " CBtz ufne,e\n",
      "fCo\n",
      "s,irs n  tdpl.\n",
      "fua----------------------------------\n",
      "Iter: 340 Loss: 3.1136574745178223\n",
      "First Citizen:\n",
      "Before we proceed any further, hearr\n",
      "  d,wC drsseof: \n",
      "esift\n",
      ".\n",
      "teresBzfopi\n",
      "\n",
      "reAtee\n",
      "uml----------------------------------\n",
      "Iter: 360 Loss: 3.1136391162872314\n",
      "First Citizen:\n",
      "Before we proceed any further, hearpoepedenweatiii.ronlfiarsretnna,setyuFeerrSrrte\n",
      "lr----------------------------------\n",
      "Iter: 380 Loss: 3.1136231422424316\n",
      "First Citizen:\n",
      "Before we proceed any further, heard : hapko n: onrsnn eshr eiernr:zp.sst e i\n",
      " p.pphS----------------------------------\n",
      "Iter: 400 Loss: 3.1136081218719482\n",
      "First Citizen:\n",
      "Before we proceed any further, hearo : :\n",
      "AasnCn\n",
      "eie.\n",
      " w,up:Y\n",
      "\n",
      "sarw\n",
      "s\n",
      "oyFaipam tsyaolz----------------------------------\n",
      "Iter: 420 Loss: 3.113596200942993\n",
      "First Citizen:\n",
      "Before we proceed any further, heare\n",
      "pi\n",
      ". l zi fyarsntp\n",
      "nipkesoap n trefwnSa. a:rorer----------------------------------\n",
      "Iter: 440 Loss: 3.1135854721069336\n",
      "First Citizen:\n",
      "Before we proceed any further, hearife:sket cepiaYe pntr re,\n",
      "kr\n",
      "noileeeYFr eA s z\n",
      "wrs----------------------------------\n",
      "Iter: 460 Loss: 3.113574743270874\n",
      "First Citizen:\n",
      "Before we proceed any further, hearteooyinmn\n",
      ",\n",
      "s oe\n",
      "lssltrkFwhoerkeku\n",
      "B\n",
      "cikApit\n",
      ":ie k----------------------------------\n",
      "Iter: 480 Loss: 3.1135659217834473\n",
      "First Citizen:\n",
      "Before we proceed any further, hear\n",
      "  sCii lmtayaztufn s\n",
      "neiy:oe u\n",
      "aeeCepetzse\n",
      "r i kp----------------------------------\n",
      "Iter: 500 Loss: 3.113557815551758\n",
      "First Citizen:\n",
      "Before we proceed any further, hear\n",
      "fl\n",
      "Aa,Be etk:,dwhtzApe\n",
      "raeF  kFipB\n",
      "e ezttissrch :----------------------------------\n",
      "Iter: 520 Loss: 3.113551139831543\n",
      "First Citizen:\n",
      "Before we proceed any further, hearht\n",
      "enFr Bt\n",
      "t:\n",
      "fosrk\n",
      "m,hrer,ereetFBpws:mB:rarcs:i\n",
      " ----------------------------------\n",
      "Iter: 540 Loss: 3.11354398727417\n",
      "First Citizen:\n",
      "Before we proceed any further, hears\n",
      ":mrmel stkofeY teiepieF: lapti enwpeta:esps,eese----------------------------------\n",
      "Iter: 560 Loss: 3.113539457321167\n",
      "First Citizen:\n",
      "Before we proceed any further, hearszA,t ili:ens ea rYuksSo r l:rtii nhie\n",
      "a\n",
      "zB\n",
      "ads Bt----------------------------------\n",
      "Iter: 580 Loss: 3.113532066345215\n",
      "First Citizen:\n",
      "Before we proceed any further, hear ,aieF,,dh:reraa  zB   ns a psseu yiea e\n",
      "pe tssksm----------------------------------\n",
      "Iter: 600 Loss: 3.113527297973633\n",
      "First Citizen:\n",
      "Before we proceed any further, hearl\n",
      "Sk\n",
      "Yit :eCapphcpiheeiwfeBsrtuk\n",
      "shetkYirhpyfi\n",
      "h n----------------------------------\n",
      "Iter: 620 Loss: 3.1135265827178955\n",
      "First Citizen:\n",
      "Before we proceed any further, hear:r \n",
      "\n",
      " fez\n",
      " ,ir eBwe\n",
      "aae\n",
      "aayrhn\n",
      "s\n",
      "spss.tslmo\n",
      "etFttp----------------------------------\n",
      "Iter: 640 Loss: 3.113520860671997\n",
      "First Citizen:\n",
      "Before we proceed any further, heareniap..:u\n",
      "kkaecee rfis\n",
      "kks\n",
      "au:ols hfY t., \n",
      "tp ezfi----------------------------------\n",
      "Iter: 660 Loss: 3.1135213375091553\n",
      "First Citizen:\n",
      "Before we proceed any further, hearfr,oyt\n",
      "SflmeBfSei  \n",
      "noiYe:nrY C.aneii:f zYrp. \n",
      "poe----------------------------------\n",
      "Iter: 680 Loss: 3.113511085510254\n",
      "First Citizen:\n",
      "Before we proceed any further, hearpihe, ye.\n",
      "iwzart s trr \n",
      "A:eh\n",
      "f\n",
      "tertme:CeiSonF\n",
      "kuan----------------------------------\n",
      "Iter: 700 Loss: 3.113523006439209\n",
      "First Citizen:\n",
      "Before we proceed any further, heare\n",
      "hC\n",
      "mra Yt eoo.kkeeft:t k FecnC  lfouii:tseke\n",
      ",a:----------------------------------\n",
      "Iter: 720 Loss: 3.1135027408599854\n",
      "First Citizen:\n",
      "Before we proceed any further, hearsirese\n",
      ",i fa:efrfureehw\n",
      "psn, \n",
      "otssne,\n",
      "rt zow\n",
      "heoef----------------------------------\n",
      "Iter: 740 Loss: 3.1135146617889404\n",
      "First Citizen:\n",
      "Before we proceed any further, hearraku,,zsr iasi\n",
      "e u.Fsu.Y\n",
      " r\n",
      "teC\n",
      "ef ofwBerle\n",
      "iak\n",
      "k ----------------------------------\n",
      "Iter: 760 Loss: 3.1135027408599854\n",
      "First Citizen:\n",
      "Before we proceed any further, hearnn\n",
      "hehoi.us eCi  ie:eikn\n",
      "e s\n",
      " iCpte,.uBrhse:Yer:e ----------------------------------\n",
      "Iter: 780 Loss: 3.113496780395508\n",
      "First Citizen:\n",
      "Before we proceed any further, heare \n",
      "cd:\n",
      " r h\n",
      "lte taanet ,n\n",
      "e   sY aee lt\n",
      "oeesrC iri----------------------------------\n",
      "Iter: 800 Loss: 3.1134934425354004\n",
      "First Citizen:\n",
      "Before we proceed any further, hearACe\n",
      "nsiilprimBeufr..ipoyd.e uermiei\n",
      "wke s rnrrieok----------------------------------\n",
      "Iter: 820 Loss: 3.1136016845703125\n",
      "First Citizen:\n",
      "Before we proceed any further, heare f nskeesa,p ,,rthse:a\n",
      "l\n",
      "sspCFtFru\n",
      "Sy sp pkC\n",
      "hnri----------------------------------\n",
      "Iter: 840 Loss: 3.1134896278381348\n",
      "First Citizen:\n",
      "Before we proceed any further, heariiahe BitepB\n",
      "rpishmroc.,uer:wp\n",
      ":e\n",
      "iaafkmhor.iw i\n",
      "w----------------------------------\n",
      "Iter: 860 Loss: 3.1134872436523438\n",
      "First Citizen:\n",
      "Before we proceed any further, hearhsasst liwaaoFepziinakrodt:\n",
      "z\n",
      "resfYfrafe wr:rpwSS ----------------------------------\n",
      "Iter: 880 Loss: 3.1134843826293945\n",
      "First Citizen:\n",
      "Before we proceed any further, hearit ss,,rnrCp:nrt  rrC iirrC\n",
      "Fe\n",
      "aekis: AcC,siioCi  ----------------------------------\n",
      "Iter: 900 Loss: 3.113483190536499\n",
      "First Citizen:\n",
      "Before we proceed any further, hear\n",
      "\n",
      " u:do.ite pkul\n",
      "eei,nlz\n",
      "aeipsruaiyia, r  rpiirir,----------------------------------\n",
      "Iter: 920 Loss: 3.1134817600250244\n",
      "First Citizen:\n",
      "Before we proceed any further, hears\n",
      " ea\n",
      ".n a t\n",
      " .,roeeres:ah\n",
      "f C i,a \n",
      "rpa ersiop yne----------------------------------\n",
      "Iter: 940 Loss: 3.1135988235473633\n",
      "First Citizen:\n",
      "Before we proceed any further, hearhp nph,zasnaii:: n rete i\n",
      " Ckreas nn.pnasAt.spYe: ----------------------------------\n",
      "Iter: 960 Loss: 3.11348295211792\n",
      "First Citizen:\n",
      "Before we proceed any further, hear\n",
      "irA p\n",
      "ktearmhoes,l.n:ee.enh\n",
      "czt ::sA \n",
      ":sSFS utkea----------------------------------\n",
      "Iter: 980 Loss: 3.113476037979126\n",
      "First Citizen:\n",
      "Before we proceed any further, hearhepsiteCCu \n",
      "renF\n",
      "zppm r.iet  e\n",
      "S:s kes rect\n",
      "tFh\n",
      "\n",
      "l----------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_data[:101],batch_size=32,block_size=100,n_iter=1000,print_every=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear cklr rekaseASoeeAsihthtS\n",
      " aeeYrt ne\n",
      "kapieCpCmeceuikaen\n",
      " fa\n",
      " hiCttsppptkrphz\n",
      "t\n",
      "ezaze ie:otn\n",
      "tn\n",
      "eesoea iueets rekrt ei ifei\n",
      "kuinat \n",
      ":k\n",
      "iS er C:tke .Yz\n",
      "lit refeattc: p\n",
      "n,zr\n",
      "\n",
      "f.wr:piiaczp:kufr.ar pk eecenstay  \n",
      "zzek n \n",
      ",miei te\n",
      "h.reesr.wClwppi: Cf  lkarsszssonAtzesoA\n",
      "seAe a  \n",
      "eeasieamff:hpeCYo\n",
      "c ryks\n",
      "r:, fadliee  nsmtrYe\n",
      "Y \n",
      "ppteanepCerl i\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11308/2194128182.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_token\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\vodin\\Documents\\Transformer\\src\\transfomer.py\u001b[0m in \u001b[0;36minference\u001b[1;34m(self, src, max_token)\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_token\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[0msrc_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblock_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                 \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m                 \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vodin\\Documents\\Transformer\\src\\transfomer.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, src)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mencoder_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoder_out\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[1;31m#out shape: (batch_size,window_size,vocab_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vodin\\.conda\\envs\\pytorchenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vodin\\Documents\\Transformer\\src\\encoder_decoder.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, encoder_out, src_mask, target_mask)\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_embed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder_layer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoder_out\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoder_out\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vodin\\.conda\\envs\\pytorchenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vodin\\Documents\\Transformer\\src\\encoder_decoder.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, enc_value, enc_key, src_mask, target_mask)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menc_key\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menc_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vodin\\.conda\\envs\\pytorchenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vodin\\Documents\\Transformer\\src\\encoder_decoder.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, key, query, value, mask)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mattention\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_norm1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mattention\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mout_ffw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_norm2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mout_ffw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vodin\\.conda\\envs\\pytorchenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vodin\\.conda\\envs\\pytorchenv\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vodin\\.conda\\envs\\pytorchenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vodin\\.conda\\envs\\pytorchenv\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vodin\\.conda\\envs\\pytorchenv\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "context = train_data[:50].reshape(1,-1).to(device)\n",
    "model.inference(context, max_token=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
